# includes/simple_template_utils.py - å®Œæ•´ä¿®æ­£ç‰ˆæœ¬

from collections import deque
import cv2
import numpy as np
import os
import time
from typing import List, Dict

class MapleStoryMonsterDetector:
    """ROæ€ªç‰©æª¢æ¸¬å™¨ - åŸºæ–¼æˆåŠŸæ¸¬è©¦çš„å¹³è¡¡åƒæ•¸"""
    
    def __init__(self, template_dir='templates\\monsters'):
        self.template_dir = template_dir
        self.templates = []
        
        # âœ… æ·»åŠ ç¼ºå¤±çš„å±¬æ€§
        self.single_templates = []
        self.animated_templates = {}  # å‹•ç•«æ¨¡æ¿å­—å…¸
        
        # æˆåŠŸçš„æª¢æ¸¬åƒæ•¸
        self.confidence_threshold = 0.08
        self.spatial_distance_threshold = 100
        self.detection_history = deque(maxlen=3)
        # ç°¡åŒ–è¨­å®š
        self.enable_roi_templates = False
        self.enable_background_removal = True
        self.bg_removal_method = 'gentle_enhancement'
        
        # åˆå§‹åŒ–æª¢æ¸¬å™¨
        self.use_sift = self._init_detector()
        self._setup_matcher()
        self._load_templates()
        self._init_animated_templates()
    
    def _init_detector(self):
        try:
            self.detector = cv2.SIFT_create(
                nfeatures=1000,
                contrastThreshold=0.04,
                edgeThreshold=10,
                sigma=1.6
            )
            self.use_sift = True   # æ”¹å›True
            print("âœ… ä½¿ç”¨SIFTæª¢æ¸¬å™¨")
            return True            # æ”¹å›True
        except AttributeError:
            self.detector = cv2.ORB_create(nfeatures=800)
            return False
    
    def _setup_matcher(self):
        """âœ… åŸºæ–¼æœç´¢çµæœ[4][9]çš„FLANNæ€§èƒ½å„ªåŒ–"""
        if self.use_sift:
            FLANN_INDEX_KDTREE = 1
            index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=3)  # å¾5é™åˆ°3
            search_params = dict(checks=30)                            # å¾50é™åˆ°30
            self.matcher = cv2.FlannBasedMatcher(index_params, search_params)
            print("âœ… ä½¿ç”¨æ€§èƒ½å„ªåŒ–FLANNåŒ¹é…å™¨")
        else:
            # ORBé…ç½®ä¿æŒä¸è®Š
            FLANN_INDEX_LSH = 6
            index_params = dict(
                algorithm=FLANN_INDEX_LSH,
                table_number=4,     # å¾6é™åˆ°4
                key_size=12,
                multi_probe_level=1
            )
            search_params = dict(checks=30)  # å¾50é™åˆ°30
            self.matcher = cv2.FlannBasedMatcher(index_params, search_params)
    
    def _load_templates(self):
        """è¼‰å…¥æ¨¡æ¿"""
        print("ğŸ“ è¼‰å…¥å¹³è¡¡ç‰ˆæ¨¡æ¿...")
        
        try:
            for item in os.listdir(self.template_dir):
                item_path = os.path.join(self.template_dir, item)
                
                if os.path.isdir(item_path):
                    for filename in os.listdir(item_path):
                        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):
                            if not self.enable_roi_templates and '_roi' in filename.lower():
                                continue
                            file_path = os.path.join(item_path, filename)
                            full_name = f"{item}/{filename}"
                            self._process_template(file_path, full_name)
                
                elif item.lower().endswith(('.png', '.jpg', '.jpeg')):
                    if not self.enable_roi_templates and '_roi' in item.lower():
                        continue
                    file_path = os.path.join(self.template_dir, item)
                    self._process_template(file_path, item)
            
            # âœ… åŒæ™‚å¡«å……single_templatesä»¥ç¢ºä¿ç›¸å®¹æ€§
            self.single_templates = self.templates.copy()
            
            original_count = sum(1 for t in self.templates if not self._is_flipped_template(t['name']))
            flipped_count = sum(1 for t in self.templates if self._is_flipped_template(t['name']))
            
            print(f"âœ… æˆåŠŸè¼‰å…¥ {len(self.templates)} å€‹å¹³è¡¡æ¨¡æ¿")
            print(f"   åŸå§‹æ¨¡æ¿: {original_count} å€‹")
            print(f"   ç¿»è½‰æ¨¡æ¿: {flipped_count} å€‹")
            
        except Exception as e:
            print(f"âŒ è¼‰å…¥æ¨¡æ¿å¤±æ•—: {e}")
    
    def _init_animated_templates(self):
        """âœ… åˆå§‹åŒ–å‹•ç•«æ¨¡æ¿å­—å…¸"""
        # æ ¹æ“šè¼‰å…¥çš„æ¨¡æ¿ç”Ÿæˆå‹•ç•«æ¨¡æ¿æ˜ å°„
        self.animated_templates = {}
        
        # æŒ‰æ€ªç‰©åç¨±åˆ†çµ„æ¨¡æ¿
        monster_groups = {}
        for template in self.templates:
            name = template['name']
            # æå–æ€ªç‰©åŸºç¤åç¨±ï¼ˆå»é™¤å‹•ä½œå’Œæ–¹å‘ï¼‰
            base_name = name.split('/')[0] if '/' in name else name.split('_')[0]
            
            if base_name not in monster_groups:
                monster_groups[base_name] = []
            monster_groups[base_name].append(template)
        
        # ç‚ºæ¯å€‹æ€ªç‰©å‰µå»ºå‹•ç•«å¹€åˆ—è¡¨
        for monster_name, templates in monster_groups.items():
            self.animated_templates[monster_name] = templates
        
        print(f"âœ… ç”Ÿæˆå‹•ç•«æ¨¡æ¿æ˜ å°„: {len(self.animated_templates)} å€‹æ€ªç‰©é¡å‹")
    
    def _process_template(self, file_path, template_name):
        """âœ… è™•ç†å–®å€‹æ¨¡æ¿ - ä½¿ç”¨é«˜ç´šç°éšè½‰æ›"""
        template_img = self._safe_imread(file_path, cv2.IMREAD_UNCHANGED)
        if template_img is None:
            return

        # è™•ç†é€æ˜åœ–
        if len(template_img.shape) == 3 and template_img.shape[2] == 4:
            alpha = template_img[:, :, 3]
            bgr = template_img[:, :, :3]
            bg = np.full(bgr.shape, 200, dtype=np.uint8)
            template_bgr = np.where(alpha[..., None] == 0, bg, bgr)
        else:
            template_bgr = template_img

        # âœ… ä½¿ç”¨é«˜ç´šç°éšè½‰æ›
        if len(template_bgr.shape) == 3:
            # âœ… ç›´æ¥ä½¿ç”¨é«˜ç´šç°éšè½‰æ›
            template_gray = self._advanced_grayscale_conversion(template_bgr)
        else:
            template_gray = template_bgr

        # æå–ç‰¹å¾µ
        kp, des = self.detector.detectAndCompute(template_gray, None)

        if des is not None and len(kp) >= 10:
            is_flipped = self._is_flipped_template(template_name)

            self.templates.append({
                'name': template_name,
                'original_name': template_name,
                'keypoints': kp,
                'descriptors': des,
                'image': template_gray,
                'size': template_gray.shape,
                'is_flipped': is_flipped
            })
    
    def _is_flipped_template(self, template_name):
        """åˆ¤æ–·æ˜¯å¦ç‚ºç¿»è½‰æ¨¡æ¿"""
        flipped_indicators = ['_flipped', '_flip', '_ç¿»è½‰', '_left', '_L']
        return any(indicator in template_name.lower() for indicator in flipped_indicators)
    
    def detect_monsters(self, game_frame: np.ndarray) -> List[Dict]:
        """âœ… ç°¡åŒ–ç‰ˆæª¢æ¸¬ç­–ç•¥"""
        if game_frame is None:
            return []
        
        scene_gray = self._advanced_grayscale_conversion(game_frame)
        
        # ç‰¹å¾µæª¢æ¸¬
        scene_kp, scene_des = self.detector.detectAndCompute(scene_gray, None)
        
        if scene_des is None:
            return []
        
        # æª¢æ¸¬æµç¨‹
        all_detections = self._detect_with_filtering(scene_kp, scene_des, scene_gray)
        
        # ç©ºé–“èšé¡
        final_detections = self._overlap_aware_clustering(all_detections)
        
        return final_detections
    
    def _overlap_aware_clustering(self, detections):
        """æ”¹é€²çš„é‡ç–Šæ„ŸçŸ¥èšé¡"""
        if not detections:
            return []
        
        # âœ… æ›´åš´æ ¼çš„å“è³ªéæ¿¾
        quality_filtered = [d for d in detections if 
                        d['confidence'] >= 0.08 and          # æé«˜æœ€ä½é–€æª»
                        d['inlier_ratio'] >= 0.5 and         # æé«˜å…§é»æ¯”ä¾‹
                        d['match_count'] >= 5]               # æé«˜åŒ¹é…è¦æ±‚
        
        # æŒ‰ä¿¡å¿ƒåº¦æ’åº
        quality_filtered.sort(key=lambda x: x['confidence'], reverse=True)
        
        clustered = []
        used_positions = []
        
        for detection in quality_filtered:
            pos = detection['position']
            too_close = False
            
            for used_pos in used_positions:
                distance = np.sqrt((pos[0] - used_pos[0])**2 + (pos[1] - used_pos[1])**2)
                
                if distance < 80:  # é©ä¸­çš„èšé¡è·é›¢
                    too_close = True
                    break
            
            if not too_close:
                clustered.append(detection)
                used_positions.append(pos)
        
        return clustered[:12]  # é™åˆ¶æœ€å¤§æª¢æ¸¬æ•¸é‡

    def _advanced_grayscale_conversion(self, scene_img):
        """âœ… ç›´æ¥è¿”å›ç°éšåœ–åƒï¼Œä¸è½‰å›BGR"""
        try:
            if len(scene_img.shape) != 3:
                return scene_img
            
            # æ¨™æº–åŠ æ¬Šå¹³å‡
            weights = np.array([0.114, 0.587, 0.299])
            gray_result = np.dot(scene_img, weights)
            
            # âœ… ç›´æ¥è¿”å›ç°éšåœ–ï¼Œä¸è½‰å›BGR
            gray_result = np.clip(gray_result, 0, 255).astype(np.uint8)
            
            return gray_result  # ç›´æ¥è¿”å›ç°éšåœ–
            
        except Exception as e:
            return cv2.cvtColor(scene_img, cv2.COLOR_BGR2GRAY)
    
    def _detect_with_filtering(self, scene_kp, scene_des, scene_gray):
        """æª¢æ¸¬ä¸¦éæ¿¾"""
        all_detections = []
        
        for template in self.templates:
            detection = self._match_template(template, scene_kp, scene_des, scene_gray)
            if detection:
                all_detections.append(detection)
        
        # æŒ‰ä¿¡å¿ƒåº¦æ’åº
        all_detections.sort(key=lambda x: x['confidence'], reverse=True)
        return all_detections
    
    def _match_template(self, template, scene_kp, scene_des, scene_gray):
        """âœ… åŸºæ–¼æœç´¢çµæœ[3]çš„é®æ“‹æ„ŸçŸ¥æ¨¡æ¿åŒ¹é…"""
        
        # âœ… æ·»åŠ ç¼ºå°‘çš„è®Šæ•¸å®šç¾©
        template_name = template['name']
        template_kp = template['keypoints']
        template_des = template['descriptors']
        is_flipped = template['is_flipped']
        
        try:
            # FLANNåŒ¹é…
            if self.use_sift:
                matches = self.matcher.knnMatch(template_des, scene_des, k=2)
            else:
                template_des_float = np.float32(template_des)
                scene_des_float = np.float32(scene_des)
                matches = self.matcher.knnMatch(template_des_float, scene_des_float, k=2)
            
            # âœ… åŸºæ–¼æœç´¢çµæœ[3]çš„æ”¹é€²SIFTåŒ¹é…
            # ä½¿ç”¨æ›´å¯¬é¬†çš„Lowe's ratio test
            good_matches = []
            for match_pair in matches:
                if len(match_pair) == 2:
                    m, n = match_pair
                    # âœ… é®æ“‹å ´æ™¯ä½¿ç”¨æ›´å¯¬é¬†çš„æ¯”ä¾‹
                    ratio_threshold = 0.75 if self.use_sift else 0.8
                    if m.distance < ratio_threshold * n.distance:
                        good_matches.append(m)
            
            # âœ… é™ä½æœ€å°åŒ¹é…è¦æ±‚ï¼ˆé©æ‡‰é®æ“‹ï¼‰
            MIN_MATCH_COUNT = 3
            if len(good_matches) < MIN_MATCH_COUNT:
                return None
            
            # âœ… åŸºæ–¼æœç´¢çµæœ[1]çš„å¤šé‡RANSACå˜—è©¦
            best_homography = None
            best_inliers = 0
            best_mask = None
            
            # å˜—è©¦ä¸åŒçš„RANSACåƒæ•¸
            ransac_configs = [
                (2.0, 0.99),  # åš´æ ¼
                (3.0, 0.95),  # æ¨™æº–
                (4.0, 0.90),  # å¯¬é¬†ï¼ˆé©åˆé®æ“‹ï¼‰
                (5.0, 0.85),  # éå¸¸å¯¬é¬†
            ]
            
            src_pts = np.float32([template_kp[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)
            dst_pts = np.float32([scene_kp[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)
            
            for threshold, confidence in ransac_configs:
                try:
                    M, mask = cv2.findHomography(src_pts, dst_pts,
                                            cv2.RANSAC, threshold, confidence)
                    
                    if M is not None:
                        inliers = np.sum(mask)
                        if inliers > best_inliers:
                            best_homography = M
                            best_inliers = inliers
                            best_mask = mask
                            
                except Exception:
                    continue
            
            if best_homography is None:
                return None
            
            inlier_ratio = best_inliers / len(good_matches)
            
            # âœ… é®æ“‹æ„ŸçŸ¥çš„å…§é»è¦æ±‚
            min_inlier_ratio = 0.3
            min_inliers = 3
            
            if inlier_ratio < min_inlier_ratio or best_inliers < min_inliers:
                return None
            
            # âœ… è¨ˆç®—æª¢æ¸¬ä½ç½®ï¼ˆä½¿ç”¨æœ€ä½³å–®æ‡‰æ€§çŸ©é™£ï¼‰
            h, w = template['size']
            pts = np.float32([[0, 0], [0, h-1], [w-1, h-1], [w-1, 0]]).reshape(-1, 1, 2)
            dst_corners = cv2.perspectiveTransform(pts, best_homography)
            
            # âœ… é®æ“‹æ„ŸçŸ¥çš„æª¢æ¸¬æ¡†é©—è­‰
            if not self._occlusion_aware_validate_box(dst_corners, scene_gray.shape):
                return None
            
            center_x = int(np.mean(dst_corners[:, 0, 0]))
            center_y = int(np.mean(dst_corners[:, 0, 1]))
            
            if not self._is_valid_position(center_x, center_y, scene_gray.shape):
                return None
            
            # âœ… é®æ“‹æ„ŸçŸ¥çš„ä¿¡å¿ƒåº¦è¨ˆç®—
            avg_distance = np.mean([good_matches[i].distance for i in range(len(good_matches)) if best_mask[i]])
            
            # åŸºæ–¼å¯è¦‹ç‰¹å¾µé»çš„æ¯”ä¾‹èª¿æ•´ä¿¡å¿ƒåº¦
            visible_ratio = best_inliers / len(template['keypoints'])  # å¯è¦‹ç‰¹å¾µé»æ¯”ä¾‹
            occlusion_penalty = max(0.5, visible_ratio)  # é®æ“‹æ‡²ç½°å› å­
            
            base_confidence = (inlier_ratio * best_inliers * 0.1) / (avg_distance * 0.01 + 1)
            confidence = base_confidence * occlusion_penalty
            
            # ç¿»è½‰ç‰ˆæœ¬é™ä½ä¿¡å¿ƒåº¦
            flip_penalty = 0.95 if is_flipped else 1.0
            confidence *= flip_penalty
            
            # âœ… é®æ“‹å ´æ™¯çš„ä¿¡å¿ƒåº¦é–€æª»æ›´ä½
            occlusion_threshold = self.confidence_threshold
            if confidence < occlusion_threshold:
                return None
            
            detection = {
                'name': template['original_name'],
                'full_name': template_name,
                'position': (center_x, center_y),
                'confidence': confidence,
                'matches': len(good_matches),
                'inliers': int(best_inliers),
                'inlier_ratio': inlier_ratio,
                'corners': dst_corners,
                'is_flipped': is_flipped,
                'direction': "ç¿»è½‰" if is_flipped else "åŸå§‹",
                'avg_distance': avg_distance,
                'template_name': template['original_name'],
                'match_count': len(good_matches),
                'timestamp': time.time(),
                'occlusion_aware': True,  # âœ… æ¨™è¨˜ç‚ºé®æ“‹æ„ŸçŸ¥æª¢æ¸¬
                'visible_ratio': visible_ratio
            }
            
            return detection
            
        except Exception as e:
            return None
    
    def _occlusion_aware_validate_box(self, corners, scene_shape):
        """âœ… åŸºæ–¼æœç´¢çµæœ[4]çš„é®æ“‹æ„ŸçŸ¥æª¢æ¸¬æ¡†é©—è­‰"""
        try:
            height, width = scene_shape
            points = corners.reshape(-1, 2)
            
            # âœ… é®æ“‹å ´æ™¯çš„æ›´å¯¬é¬†ç¯„åœæª¢æŸ¥
            margin = 150  # å¢åŠ å®¹å¿åº¦
            for point in points:
                x, y = point
                if x < -margin or x > width + margin or y < -margin or y > height + margin:
                    return False
            
            # âœ… é®æ“‹å ´æ™¯çš„é¢ç©æª¢æŸ¥
            box_area = cv2.contourArea(points)
            scene_area = height * width
            
            # å…è¨±æ›´å¤§çš„æª¢æ¸¬æ¡†ï¼ˆå¯èƒ½åŒ…å«é®æ“‹ç‰©ï¼‰
            if box_area > scene_area * 0.5 or box_area < 100:  # æ›´å¯¬é¬†
                return False
            
            # âœ… é®æ“‹å ´æ™¯çš„é•·å¯¬æ¯”æª¢æŸ¥
            rect = cv2.minAreaRect(points)
            (center, (w, h), angle) = rect
            
            if w > 0 and h > 0:
                aspect_ratio = max(w, h) / min(w, h)
                if aspect_ratio > 8.0:  # æ›´å¯¬é¬†çš„é•·å¯¬æ¯”ï¼ˆé®æ“‹å¯èƒ½é€ æˆè®Šå½¢ï¼‰
                    return False
            
            return True
            
        except Exception as e:
            return False
    
    def _is_valid_position(self, x, y, shape):
        """ä½ç½®æœ‰æ•ˆæ€§æª¢æŸ¥"""
        height, width = shape
        return not (x < 40 or x > width - 40 or y < 40 or y > height - 40)
    
    def _safe_imread(self, image_path, flags=cv2.IMREAD_COLOR):
        """å®‰å…¨è®€å–"""
        try:
            img_array = np.fromfile(image_path, dtype=np.uint8)
            return cv2.imdecode(img_array, flags)
        except Exception:
            return None
    
    def detect_and_save_result(self, game_frame: np.ndarray) -> List[Dict]:
        """æª¢æ¸¬ä¸¦ä¿å­˜çµæœ"""
        detections = self.detect_monsters(game_frame)
        
        if detections:
            result_img = self.debug_show_detections_with_boxes(game_frame, detections)
            if result_img is not None:
                timestamp = int(time.time())
                cv2.imwrite(f"detection_result_{timestamp}.png", result_img)
                print(f"ğŸ¯ æª¢æ¸¬å®Œæˆ: {len(detections)} å€‹çµæœï¼Œå·²ä¿å­˜åœ–ç‰‡")
        else:
            timestamp = int(time.time())
            cv2.imwrite(f"no_detection_{timestamp}.png", game_frame)
            print("ğŸ“¸ ç„¡æª¢æ¸¬çµæœï¼Œå·²ä¿å­˜åŸå§‹ç•«é¢")
        
        return detections
    
    def debug_show_detections_with_boxes(self, game_frame: np.ndarray, detections: List[Dict], save_image: bool = True):
        """å¯è¦–åŒ–æª¢æ¸¬çµæœ"""
        return self.create_detection_visualization(game_frame, detections)
    
    def create_detection_visualization(self, game_frame, detections):
        """å‰µå»ºæª¢æ¸¬å¯è¦–åŒ–"""
        try:
            result_image = game_frame.copy()
            
            for i, detection in enumerate(detections):
                # æ ¹æ“šä¿¡å¿ƒåº¦é¸æ“‡é¡è‰²
                confidence = detection['confidence']
                if confidence >= 0.15:
                    color = (0, 255, 0)      # ç¶ è‰²ï¼šé«˜ä¿¡å¿ƒåº¦
                elif confidence >= 0.08:
                    color = (0, 255, 255)    # é»ƒè‰²ï¼šä¸­ä¿¡å¿ƒåº¦
                else:
                    color = (255, 0, 255)    # ç´«è‰²ï¼šä½ä¿¡å¿ƒåº¦
                
                # ç•«é‚Šç•Œæ¡†
                corners = detection['corners']
                cv2.polylines(result_image, [np.int32(corners)], True, color, 2)
                
                # ç•«ä¸­å¿ƒé»
                center = detection['position']
                cv2.circle(result_image, center, 6, color, -1)
                
                # æ¨™ç±¤ä¿¡æ¯
                direction = "ç¿»" if detection['is_flipped'] else "åŸ"
                monster_name = detection['name'].split('/')[-1].replace('.png', '')
                label = f"{i+1}.{monster_name}({direction})"
                confidence_label = f"{confidence:.3f}"
                
                # é¡¯ç¤ºè·é›¢ï¼ˆå¦‚æœæœ‰ï¼‰
                if 'distance' in detection:
                    distance_label = f"è·é›¢:{detection['distance']:.1f}"
                    cv2.putText(result_image, distance_label, (center[0]-20, center[1]+30),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.3, color, 1)
                
                # ä¸»æ¨™ç±¤
                cv2.putText(result_image, label, (center[0]-40, center[1]-20),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
                
                # ä¿¡å¿ƒåº¦æ¨™ç±¤
                cv2.putText(result_image, confidence_label, (center[0]-15, center[1]+15),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)
            
            return result_image
            
        except Exception as e:
            return None
    
    # âœ… ä¿æŒç›¸å®¹æ€§çš„æ–¹æ³•
    def get_animation_info(self):
        """ä¿æŒåŸæœ‰ä»‹é¢ç›¸å®¹æ€§"""
        return {
            'total_templates': len(self.templates),
            'single_templates': len(self.single_templates),
            'animated_templates': len(self.animated_templates),  # âœ… æ·»åŠ å‹•ç•«æ¨¡æ¿è¨ˆæ•¸
            'detection_method': 'balanced_sift_flann',
            'confidence_threshold': self.confidence_threshold
        }
    
    def get_monster_info(self):
        """ä¿æŒåŸæœ‰ä»‹é¢ç›¸å®¹æ€§"""
        return {
            'loaded_monsters': len(set(t['name'].split('/')[0] for t in self.templates if '/' in t['name'])),
            'total_templates': len(self.templates),
            'single_templates': len(self.single_templates),
            'animated_templates': len(self.animated_templates),  # âœ… æ·»åŠ å‹•ç•«æ¨¡æ¿è¨ˆæ•¸
            'detection_threshold': self.confidence_threshold,
            'detection_method': 'balanced'
        }
    
    def get_single_template_info(self):
        """ç²å–å–®ä¸€æ¨¡æ¿ä¿¡æ¯ï¼ˆç›¸å®¹æ€§æ–¹æ³•ï¼‰"""
        return {
            'total_single_templates': len(self.single_templates),
            'template_names': [t['name'] for t in self.single_templates],
            'detection_method': 'balanced_sift_flann'
        }
    
    def save_current_frame_and_templates(self, game_frame: np.ndarray):
        """ä¿å­˜ç•¶å‰ç•«é¢å’Œæ¨¡æ¿"""
        try:
            timestamp = int(time.time())
            cv2.imwrite(f"current_frame_{timestamp}.png", game_frame)
            print(f"ğŸ“¸ ä¿å­˜ç•¶å‰ç•«é¢")
        except Exception as e:
            print(f"âŒ ä¿å­˜å¤±æ•—: {e}")

    def find_target_monster(self, game_frame, player_screen_pos):
        """âœ… æ€ªç‰©ç›®æ¨™é¸æ“‡é‚è¼¯"""
        try:
            # åŸ·è¡Œæ€ªç‰©æª¢æ¸¬
            detected_monsters = self.detect_monsters(game_frame)
            
            if not detected_monsters:
                return None
            
            # æŒ‰ä¿¡å¿ƒåº¦é¸æ“‡æœ€ä½³ç›®æ¨™
            best_target = None
            best_score = 0
            
            for monster in detected_monsters:
                # ä¿¡å¿ƒåº¦åˆ†æ•¸
                confidence_score = monster['confidence']
                
                # ç¶œåˆåˆ†æ•¸ï¼ˆæš«æ™‚åªç”¨ä¿¡å¿ƒåº¦ï¼Œè·é›¢è¨ˆç®—è¤‡é›œï¼‰
                total_score = confidence_score
                
                if total_score > best_score:
                    best_score = total_score
                    best_target = monster
            
            if best_target:
                print(f"ğŸ¯ é¸æ“‡ç›®æ¨™: {best_target['name']} åˆ†æ•¸:{best_score:.3f}")
            
            return best_target
            
        except Exception as e:
            print(f"âŒ æ€ªç‰©ç›®æ¨™é¸æ“‡å¤±æ•—: {e}")
            return None

    def load_templates_from_folder(self, folder_path: str) -> bool:
        """å¾æŒ‡å®šè³‡æ–™å¤¾è¼‰å…¥æ€ªç‰©æ¨¡æ¿"""
        try:
            if not os.path.exists(folder_path):
                print(f"âŒ æ‰¾ä¸åˆ°æ¨¡æ¿è³‡æ–™å¤¾: {folder_path}")
                return False
            
            # æ¸…ç©ºç¾æœ‰æ¨¡æ¿
            self.templates = []
            self.animated_templates = {}
            
            # è¼‰å…¥æ–°æ¨¡æ¿
            template_files = [f for f in os.listdir(folder_path) 
                            if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
            
            if not template_files:
                print(f"âš ï¸ è³‡æ–™å¤¾ä¸­æ²’æœ‰æ‰¾åˆ°æ¨¡æ¿åœ–ç‰‡: {folder_path}")
                return False
            
            print(f"ğŸ“ è¼‰å…¥æ¨¡æ¿è³‡æ–™å¤¾: {folder_path}")
            print(f"ğŸ” æ‰¾åˆ° {len(template_files)} å€‹æ¨¡æ¿æª”æ¡ˆ")
            
            # è¼‰å…¥æ¯å€‹æ¨¡æ¿
            for template_file in template_files:
                template_path = os.path.join(folder_path, template_file)
                template_img = self._safe_imread(template_path)
                
                if template_img is None:
                    print(f"âš ï¸ ç„¡æ³•è¼‰å…¥æ¨¡æ¿: {template_file}")
                    continue
                
                # æå–æ€ªç‰©åç¨±ï¼ˆå»é™¤å‰¯æª”åï¼‰
                monster_name = os.path.splitext(template_file)[0]
                
                # è¨ˆç®—ç‰¹å¾µé»
                gray = cv2.cvtColor(template_img, cv2.COLOR_BGR2GRAY)
                keypoints, descriptors = self.detector.detectAndCompute(gray, None)
                
                if descriptors is None:
                    print(f"âš ï¸ ç„¡æ³•æå–ç‰¹å¾µé»: {template_file}")
                    continue
                
                # æ·»åŠ åˆ°æ¨¡æ¿åˆ—è¡¨
                template = {
                    'name': monster_name,
                    'original_name': monster_name,
                    'image': template_img,
                    'keypoints': keypoints,
                    'descriptors': descriptors,
                    'size': template_img.shape[:2][::-1],  # (width, height)
                    'is_flipped': False  # æ·»åŠ  is_flipped å±¬æ€§
                }
                
                self.templates.append(template)
            
            # åˆå§‹åŒ–å‹•ç•«æ¨¡æ¿
            self._init_animated_templates()
            
            print(f"âœ… æˆåŠŸè¼‰å…¥ {len(self.templates)} å€‹æ¨¡æ¿")
            return True
            
        except Exception as e:
            print(f"âŒ è¼‰å…¥æ¨¡æ¿å¤±æ•—: {e}")
            return False

class UITemplateHelper:
    def __init__(self, adb, cooldown_interval=0.7):
        self.adb = adb
        self.cooldown = {}
        self.cooldown_interval = cooldown_interval

    def detect_and_click(self, frame, template_path, label, color, key, now, threshold=0.7):
        import os
        import cv2
        if key not in self.cooldown:
            self.cooldown[key] = 0
        if now - self.cooldown[key] > self.cooldown_interval:
            if frame is not None and os.path.exists(template_path):
                match = self.match_template(frame, template_path, threshold=threshold)
                if match:
                    x, y, w, h = match
                    cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)
                    cv2.putText(frame, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
                    if self.adb:
                        self.adb.click_ui(x, y, w, h)
                    self.cooldown[key] = now
                    return True
        return False

    def match_template(self, frame, template_path, threshold=0.7):
        import cv2
        import numpy as np
        template = cv2.imread(template_path, cv2.IMREAD_COLOR)
        if template is None or frame is None:
            return None
        # è½‰ç°éš
        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) if len(frame.shape) == 3 else frame
        template_gray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY) if len(template.shape) == 3 else template
        res = cv2.matchTemplate(frame_gray, template_gray, cv2.TM_CCOEFF_NORMED)
        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)
        if max_val >= threshold:
            h, w = template_gray.shape[:2]
            return (max_loc[0], max_loc[1], w, h)
        return None

# å‰µå»ºä¸¦å°å‡ºæ€ªç‰©æª¢æ¸¬å™¨å¯¦ä¾‹
monster_detector = MapleStoryMonsterDetector()
print("âœ… æ€ªç‰©æª¢æ¸¬å™¨å·²åˆå§‹åŒ–")
